# 强化学习在大语言模型训练中的应用

本仓库是对[大规模语言模型：从理论到实践](https://intro-llm.github.io/)一书第六章强化学习部分的内容讲解。包括介绍强化学习基本概念的示例代码和对应的PPT。

概念涉及强化学习中的Q-learning、DQN，策略梯度，广义优势估计，重要性采样，近端策略优化等。

参考书目包括：

- [大规模语言模型：从理论到实践](https://intro-llm.github.io/)
- [动手学强化学习](https://hrl.boyuai.com/)
- [蘑菇书EasyRL](https://datawhalechina.github.io/easy-rl/#/)
- [Secrets of RLHF in Large Language Models Part I: PPO](https://arxiv.org/abs/2307.04964)
- [Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347v2)
- [Learning to summarize from human feedback](https://arxiv.org/abs/2009.01325v3)

参考博客

- [深度强化学习之深度Q网络DQN详解](https://zhuanlan.zhihu.com/p/145102068)
- [ChatGPT原理详解+实操(1)----SFT(GPT模型精调)](https://zhuanlan.zhihu.com/p/609795142)
- [ChatGPT原理详解+实操(2)----RM(reward model)](https://zhuanlan.zhihu.com/p/610147705)
- [复旦NLP组开源PPO-Max](https://www.51cto.com/article/761044.html)
- [想训练ChatGPT？得先弄明白Reward Model怎么训（附源码）](https://mp.weixin.qq.com/s/1v4Uuc1YAZ9MRr1UWMH9xw)
- [LLM常见问题（强化学习部分）](https://juejin.cn/post/7302993899106713600)
- [KL散度(Kullback-Leibler Divergence)介绍及详细公式推导](https://hsinjhao.github.io/2019/05/22/KL-DivergenceIntroduction/)
- [初学机器学习：直观解读KL散度的数学概念](https://www.jiqizhixin.com/articles/2018-05-29-2)
- ...
